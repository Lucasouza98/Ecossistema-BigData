acessar mysql
docker exec -it database bash
mysql -psecret
show databases;
use employees;
show tables;

1. Criar a tabela cp_titles_date, contendo a cópia da tabela titles com os campos title e to_date
create table cp_titles_date as select title, to_date from titles;

2. Pesquisar os 15 primeiros registros da tabela cp_titles_date
select * from cp_titles_date limit 15;

3. Alterar os registros do campo to_date para null da tabela cp_titles_date, quando o título for igual a Staff
update cp_titles_date set to_date = NULL where title = 'Staff'

Realizar com uso do Sqoop - Importações no warehouse /user/hive/warehouse/db_test_<numero_questao> e visualizar no HDFS
sqoop import --table cp_titles_date --connect jdbc:mysql://database/employees --username=root --password=secret --warehouse-dir /user/hive/warehouse/employees_cp_titles -m 1
hadoop fs -ls /user/hive/warehouse/employees_cp_titles/cp_titles_date
hdfs dfs -cat /user/hive/warehouse/employees_cp_titles/cp_titles_date/part-m-00000 | head -n 5

4. Importar a tabela titles com 8 mapeadores no formato parquet
sqoop import --table titles --connect jdbc:mysql://database/employees --username=root --password=secret --as-parquetfile --warehouse-dir /user/hive/warehouse/db_tbtitles_map_parquet -m 8

5. Importar a tabela titles com 8 mapeadores no formato parquet e compressão snappy
sqoop import --table titles --connect jdbc:mysql://database/employees --username root --password secret -m 8 --as-parquetfile --warehouse-dir /user/hive/warehouse/db_test2_5 --compress --compression-codec org.apache.hadoop.io.compress.SnappyCodec

6. Importar a tabela cp_titles_date com 4 mapeadores (erro)
sqoop import --table cp_titles_date --connect jdbc:mysql://database/employees --username root --password secret -m 4 --warehouse-dir /user/hive/warehouse/db_test2_6

Importar a tabela cp_titles_date com 4 mapeadores divididos pelo campo título no warehouse /user/hive/warehouse/db_test2_title
sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --table cp_titles_date --connect jdbc:mysql://database/employees --username root --password secret -m 4 --warehouse-dir /user/hive/warehouse/db_test2_title --split-by title

Importar a tabela cp_titles_date com 4 mapeadores divididos pelo campo data no warehouse /user/hive/warehouse/db_test2_date
 sqoop import -Dorg.apache.sqoop.splitter.allow_text_splitter=true --table cp_titles_date --connect jdbc:mysql://database/employees --username root --password secret -m 4 --warehouse-dir /user/hive/warehouse/db_test2_title --split-by to_date -delete-target-dir

Qual a diferença dos registros nulos entre as duas importações?

